---
title:  "Canary project - counting lines of code"
output: github_document
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)
require(tidyverse)
library(plotly)
require(janitor)
require(skimr)
library(mosaic)
library(inspectdf)
library(visdat)
library(DT)
# knitr chunk options ----
knitr::opts_chunk$set(
  echo = TRUE, # show/hide all code
  # results = "hide", # hide results
  tidy = FALSE, # cleaner code printing
  comment = "#> ", # better console printing
  eval = TRUE, # turn this to FALSE stop code chunks from running
  message = TRUE, # show messages
  fig.width = 8, # figure width
  fig.height = 6, # figure height
  warning = FALSE, # show warnings
  size = "small", # size of the text
  fig.path = "figs/"
) # location of files
# knit settings ----
knitr::opts_knit$set(
  width = 78
)
# base options ----
base::options(
  tibble.print_max = 25,
  tibble.width = 78,
  scipen = 100000000,
  max.print = 999999
)
```

Check out the repository for this project [here](https://github.com/mjfrigaard/tech-debt-git-project).

```{r set-theme}
ggplot2::theme_set(hrbrthemes::theme_ipsum_tw(base_family = "Titillium Web", 
                                           base_size = 8, 
                                           axis_text_size = 9,
                                            plot_title_family = "DroidSansMono",
                                             plot_title_size = 13))
```

# Counting lines of code

To count the lines of code in Github files (or in any local directory) we will be using the [`cloc` command line tool](https://github.com/AlDanial/cloc) and the [`cloc` R package](https://github.com/hrbrmstr/cloc). 

The exerpt below is from the [Software Design X-Rays](https://pragprog.com/book/atevol/software-design-x-rays) text (we will refer to this as `SDX` from here forward):

> This appendix contains a brief summary of the data mining commands used throughout the book. Thereâ€™s also a brief introduction to `cloc` as a proxy for complexity metrics, and a quick look at the planned support for exporting analysis data from CodeScene.

## Command line `cloc` tool

In the terminal window, we will download the `cloc` package and see if we can't count some lines of code. 

```{bash install-cloc, eval=FALSE}
# check for installation
brew install cloc
# Warning: cloc 1.82 is already installed and up-to-date
# To reinstall 1.82, run `brew reinstall cloc`
```

This is good news for me! Now I am going to use the `ggplot2` package because it's used all the time and very stable (and I will be using it explore these data, too). Below we will outline a Github analysis on the [`ggplot2`](https://github.com/tidyverse/ggplot2) repository.

## R `cloc` package

We will break down how to use the `cloc` tool and the `cloc` package on the [`ggplot2`](https://github.com/tidyverse/ggplot2) repo to see if they work on a project we're somewhat familiar with. 

```{r load-cloc}
library(cloc)
```

## Get the Age of Your Code

The next section covers the age of their code, a process that takes two steps, 

> 1. first we fetch a list of all files in the repository with the `git ls-files` command, 

> 2. then we request the modification date of each file using a variation of `git log`, as shown in the next example:

These are the worst directions in the book, because we only get a list of files,

```{bash list-files}
# change dir
cd ../ggplot2 
# get the list of files
git ls-files | head -n 10
```

And a list of dates

```{bash log-dates}
# change dir
cd ../ggplot2 
# get the dates for the file
git log --format="%ad" --date=short | head -n 10
```

We can put both of these into text files and see what we can do to combine them. 

```{bash create-file-dates-list}
# change dir
cd ../ggplot2 
# create file
touch "file_list.txt"
# get the list of files
git ls-files >> file_list.txt
# create file
touch "file_dates.txt"
# get the dates for the file
git log --format="%ad" --date=short >> file_dates.txt
```

Move these into project folder. 

```{r move-file-data}
fs::file_move(path = "../ggplot2/file_list.txt", 
              new_path = paste0("data/",
                                base::noquote(lubridate::today()),
                                "-file_list.txt"))
fs::file_move(path = "../ggplot2/file_dates.txt", 
              new_path = paste0("data/",
                                base::noquote(lubridate::today()),
                                "-file_dates.txt"))
fs::dir_ls("data")
```

Great! Now we can move onto the `cloc` program.

# Using `cloc` to get the lines of code

This block runs the `cloc` command line tool. 

```{bash cloc}
# change dir
cd ../ggplot2
# create file for cloc output
touch "ggplot2_cloc.txt"
# run cloc
cloc . --quiet 
# save to file
cloc . --quiet >> "ggplot2_cloc.txt"
```

We will create this in a .csv file in the code chunk below, then view the new file.

```{bash csv-file}
# change dir
cd ../ggplot2
# save output to file
cloc ./ --by-file --csv --quiet --report-file=ggplot2_lines_by_file.csv
# check new file
head -n 10 ggplot2_lines_by_file.csv 
```

This output comes with some meta data `"github.com/AlDanial/cloc v 1.82  T=0.86 s (596.7 files/s, 87011.5 lines/s)"`, telling us the number of files and lines. 

We will move these data into our local folder and load these data into RStudio. 

```{r move-cloc-csv}
# fs::dir_ls("../ggplot2")
fs::file_move(path = "../ggplot2/ggplot2_lines_by_file.csv", 
              new_path = paste0("data/", 
                                base::noquote(lubridate::today()), 
                                "-ggplot2_lines_by_file.csv"))
fs::dir_ls("data")
```

Now we can load these data back into RStudio.

```{r Ggplot2LinesByFileRAW}
Ggplot2LinesByFileRAW <- readr::read_csv(file = paste0("data/",
                                              base::noquote(lubridate::today()), 
                                "-ggplot2_lines_by_file.csv")) %>% 
  dplyr::select(-dplyr::contains("github.com"))
Ggplot2LinesByFileRAW %>% base::names()
```

We need to make a few adjustments here, because `filename` isn't totally accurate here (it's `cloc_path`).

```{r rename-filename}
# rename filename to filepath 
Ggplot2LinesByFile <- Ggplot2LinesByFileRAW %>% 
  dplyr::rename(cloc_path = filename)
Ggplot2LinesByFile %>% dplyr::glimpse(78)
```

Reorganize files

```{r create-filename}
# create filename 
Ggplot2LinesByFile <- Ggplot2LinesByFile %>% 
  dplyr::mutate(filename = base::basename(cloc_path)) %>% 
  dplyr::select(language, 
                filename, 
                cloc_path, 
                dplyr::everything())
```

For some reason, this .csv includes the `SUM`. 

```{r check-SUM}
Ggplot2LinesByFile %>% dplyr::count(language, sort = TRUE)
```

We will remove this below. 

```{r remove-SUM}
Ggplot2LinesByFile <- Ggplot2LinesByFile %>% dplyr::filter(language != "SUM") 
```

# Visualize lines of code per language

Now we can visualize the `cloc` data in the graph below. 

```{r code-visualize}
Ggplot2LinesByFile %>% 
  group_by(language) %>% 
  dplyr::arrange(desc(code)) %>% 
  utils::head(25) %>% 
      ggplot2::ggplot(aes(x = fct_reorder(.f = filename,
                                          .x = code),
                          y = code, 
                          color = language)) + 
  ggplot2::geom_point(aes(color = language), 
             show.legend = FALSE) + 
  ggplot2::coord_flip() + 
  ggplot2::facet_wrap(. ~ language, 
             scales = "free") + 
  ggplot2::labs(y = "Lines of code", 
       x = "Name of file",
       title = "Top 25 lines of code by filename",
       caption = "cloc ./ --by-file --csv --quiet --report-file=file.csv")
```

We can see the number of lines is highest in the Markdown files. Specifically, `failure.md`, `problems.md`, and `NEWS.md` had the highest number of Markdown code lines. 

Now we can join this to the `GitFileCount` data. But first we should figure out how many files are listed in the data sets. 

```{r find-GitFileCount}
fs:::dir_tree("data", regex = "2019-10-09")
```

```{r import-GitFileCount}
# fs:::dir_tree("data", regex = as.character(lubridate::today()))
GitFileCount <- readr::read_csv("data/2019-10-09-GitFileCount.csv")
```

Here is the distinct number of `filename`s in `GitFileCount` *and* the distinct number of `filename`s in `Ggplot2LinesByFile`:

```{r check-distinct-filename}
GitFileCount %>% distinct(filename) %>% base::nrow(x = .)
Ggplot2LinesByFile %>% distinct(filename) %>% base::nrow(x = .)
```

There are more `filename`s in the `GitFileCount` than in the `Ggplot2LinesByFile` data set, this is a bit strange but makes sense if we're considering the two data sets. One is measuring how many changes have been made to files/folders *over time*, the other is measuring the number of lines in each *existing* file. 

This is why there are more file paths, too.

```{r check-distinct-file-paths}
GitFileCount %>% distinct(gitlog_path) %>% base::nrow(x = .)
Ggplot2LinesByFile %>% distinct(cloc_path) %>% base::nrow(x = .)
```

If we count `filename`s, we can see there are 66 files that show up more than once in the `GitFileCount` file.

```{r count-filenames}
GitFileCount %>% 
  dplyr::count(filename, sort = TRUE) %>% 
  dplyr::filter(n > 1)
```

But in contrast, there are only 2 in the `Ggplot2LinesByFile`, and they are both `README.md`.

```{r count-filename-Ggplot2LinesByFile}
Ggplot2LinesByFile %>% count(filename) %>% dplyr::filter(n > 1)
```

We can `left_join` these and create a new `GgplotGitClocData` data set. 

```{r GgplotGitClocData}
GgplotGitClocData <- GitFileCount %>% 
                               dplyr::left_join(Ggplot2LinesByFile, 
                                                    by = "filename")
```

`GgplotGitClocData` has the file changes and lines of code in the same data set. Next we will check out the other variables in this data set. 

```{r GgplotGitClocData-skim}
GgplotGitClocData %>% 
  skimr::skim()
```


Export this file with a timestamp

```{r export-GgplotGitClocData}
readr::write_csv(as.data.frame(GgplotGitClocData), 
                 path = paste0("data/",
                               base::noquote(lubridate::today()), 
                                "-GgplotGitClocData.csv"))
fs::dir_tree("data", regex = "-GgplotGitClocData.csv")
```

## Examine the missing data 

These are the missing data in the `GgplotGitClocData`.

```{r vis_miss}
visdat::vis_miss(GgplotGitClocData) + ggplot2::coord_flip()
```

This makes sense, because we have to have `file_changes`, `gitlog_path`, and `filename`. The graph below is showing the same data in a slightly different way.

```{r check-out-inspect_na}
inspectdf::inspect_na(GgplotGitClocData) %>% show_plot() 
```

## blank, comment & code 

The `blank` variable is measuring the number of blank lines, calculated by substracting the *total non-blank number of lines* from the *total number of lines in the file*.

blank lines = **L** `total lines in file` - **L** `non_blank`

The `comment` variable is the non-blank lines minus the total lines of code.

comment lines = **L** `non_blank` - **L** `code`

The `code` lines are the remaining total lines of code. 

code lines = **L** `code`

```{r skim-cloc-variables}
GgplotGitClocDataSkimList <- GgplotGitClocData %>% 
  dplyr::select(blank, comment, code) %>% 
  skimr::skim_to_list()
GgplotGitClocDataSkimList$numeric
```

Missing the `language` variable, and if we check these files, we can see they are mostly the `.Rd` files.  

```{r check-missing-languages}
GgplotMissingLangGitClocData <- GgplotGitClocData %>% 
  dplyr::filter(is.na(language))
DT::datatable(GgplotMissingLangGitClocData)
```

## Percentage breakdown of languages

Below is a table breakdown of languages per file. 

```{r LangTibble}
knitr::kable(
GgplotGitClocData %>% 
  janitor::tabyl(language) %>%
  janitor::adorn_pct_formatting(dat = .) %>%
  janitor::adorn_rounding(dat = ., digits = 1) %>%
  tibble::as_tibble() %>%
  dplyr::arrange(desc(`n`)))
```

Below is another table of language counts. 

```{r LangCount}
LangCount <- GgplotGitClocData %>% 
  count(language, sort = TRUE)
DT::datatable(LangCount)
```

