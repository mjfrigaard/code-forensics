Git log data - file changes
================
2020-02-10

``` r
library(cloc) # cloc (counting lines of code)
library(gh) # github api package
library(tidyverse) # tidy analysis tools
library(tidymodels) # tidy modeling
library(tidygraph) # tidy graphs
library(tidytext) # text analysis for commit messages 
library(ggraph) # graphing
library(janitor) # cleaning data
library(inspectdf) # visualizing entire data sets 
library(skimr) # summary stats 
library(visdat) # missing data
```

Check out the repository for this project [here]().

# Motivation

This document covers how to use the `git log` to get meaningful metrics
about your workflow and code. Great resources for learning how to use
the `git log` tools are,

1)  the [online git documentation](https://git-scm.com/doc),
2)  [Professional
    Git](https://www.amazon.com/Professional-Git-Brent-Laster/dp/111928497X),  
3)  [Pro Git](https://git-scm.com/book/en/v2) and  
4)  [Git for Teams](http://gitforteams.com/)

## An example repo

In order to replicate the work in the Appendix 3 of Software Design
X-Rays (which covers author summaries, `cloc`, and complexity), we’ll
need a repo. I’ve chosen the `ggplot2` repository because it’s fairly
common (and I know it’s widely used by data scientists).

Below is a code chunk to clone the `ggplot2` repo from Github into the
parent folder.

``` bash
cd downloads
pwd
git clone https://github.com/tidyverse/ggplot2.git
```

Let’s check the contents of this downloaded folder.

``` r
fs::dir_tree("downloads/ggplot2", recurse = FALSE)
```

    #>  downloads/ggplot2
    #>  ├── CODE_OF_CONDUCT.md
    #>  ├── CONTRIBUTING.md
    #>  ├── DESCRIPTION
    #>  ├── GOVERNANCE.md
    #>  ├── ISSUE_TEMPLATE.md
    #>  ├── LICENSE
    #>  ├── LICENSE.md
    #>  ├── NAMESPACE
    #>  ├── NEWS
    #>  ├── NEWS.md
    #>  ├── R
    #>  ├── README.Rmd
    #>  ├── README.md
    #>  ├── _pkgdown.yml
    #>  ├── appveyor.yml
    #>  ├── codecov.yml
    #>  ├── cran-comments.md
    #>  ├── data
    #>  ├── data-raw
    #>  ├── ggplot2.Rproj
    #>  ├── icons
    #>  ├── inst
    #>  ├── man
    #>  ├── pkgdown
    #>  ├── revdep
    #>  ├── tests
    #>  └── vignettes

## Folder structures

For the sake of reproduction, the folder structure for this project is
below.

``` r
fs::dir_tree(".", recurse = FALSE)
```

    #>  .
    #>  ├── 01.0-git-file-changes-R.Rmd
    #>  ├── 02.0-git-author-data-R.Rmd
    #>  ├── 03.1-tidy-git-analysis-jackson.Rmd
    #>  ├── 03.2-gh-purrr-package-byran.Rmd
    #>  ├── CHANGELOG.md
    #>  ├── CITATION
    #>  ├── EXAMPLES.md
    #>  ├── LICENSE
    #>  ├── README.Rmd
    #>  ├── README.md
    #>  ├── code
    #>  ├── data
    #>  ├── doc
    #>  ├── docs
    #>  ├── downloads
    #>  ├── figs
    #>  ├── git-logs.Rproj
    #>  ├── helpers.md
    #>  ├── requirements.txt
    #>  └── results

### Path to `ggplot2` folder

The path to the `ggplot2` package folder is here:

``` r
ggplot2_folder_path <- here::here("downloads", "ggplot2")
ggplot2_folder_path
```

    #>  [1] "/Users/martinfrigaard/Dropbox/@wrkng-projects/02-unpaid/@aperture-marketing/code-forensics/git-logs/downloads/ggplot2"

We can run `bash` scritps in RStudio, so let’s walk through the `regex`
pattern.

From `SDX`(page 8):

> We use the same mental processes to understand code as those we use in
> everyday life beyond our keyboards (evolution wasn’t kind enough to
> equip our brains with a coding center).

> As we learn a topic we build mental representations of that domain.
> Psychologists refer to such mental models as schemas. A schema is a
> theoretical construct used to describe the way we organize knowledge
> in our memory and how we use that knowledge for a particular event.
> **You can think of a schema as a mental script implemented in neurons
> rather than code.**

This is a handy way to think about code.

## Command line tools/regex for Hotspots

> The command then counts the frequency of the resulting file names and
> delivers the results sorted in descending order:

The regex pattern below is using the pipe `|` operator to chain together
the git and unix commands.

### Extracting `git log` data

The `git log` command returns a log of all commits. We add three
options: 1.
[`--format=format:`](https://git-scm.com/docs/git-log#_commit_formatting).
This tells git how to return the logs.

2.  [`--name-only`](https://git-scm.com/docs/git-log#Documentation/git-log.txt---name-only).
    This is the name of the changed files.

3.  `head -n 20` - We will look at the top 20 lines from this command.

<!-- end list -->

``` bash
# change working directory
cd downloads/ggplot2 
# verify
pwd 
# /Users/martinfrigaard/@Working/tech-debt/ggplot2
# now run the regex with cloc
git log --format=format: --name-only | head -n 20
```

    #>  /Users/martinfrigaard/Dropbox/@wrkng-projects/02-unpaid/@aperture-marketing/code-forensics/git-logs/downloads/ggplot2
    #>  R/plot.r
    #>  
    #>  R/layout.R
    #>  tests/testthat/test-scales.r
    #>  
    #>  R/aes.r
    #>  man/aes_.Rd
    #>  
    #>  R/annotation-map.r
    #>  man/annotation_map.Rd
    #>  
    #>  DESCRIPTION
    #>  NEWS.md
    #>  
    #>  DESCRIPTION
    #>  NEWS.md
    #>  
    #>  NEWS.md
    #>  
    #>  R/guides-axis.r

There are too many lines and whitespace between each output, so it needs
some wrangling.

### egrep

The `egrep` command removes all the lines in between each commit log
item. Read more
[here](https://earthsci.stanford.edu/computing/unix/editing/grep.php).

The added `-v` tells bash the “selected lines are those **not** matching
any of the specified patterns.”

``` bash
# change dir
cd downloads/ggplot2 
git log --format=format: --name-only | egrep -v '^$' | head -n 10
```

    #>  R/plot.r
    #>  R/layout.R
    #>  tests/testthat/test-scales.r
    #>  R/aes.r
    #>  man/aes_.Rd
    #>  R/annotation-map.r
    #>  man/annotation_map.Rd
    #>  DESCRIPTION
    #>  NEWS.md
    #>  DESCRIPTION

This cleans the output up and removes some of the whitespace.

### sort and unique

The next few commands sorts the output from the Git log, and then
collapses them to each unique entry.

1.  The first [`sort`](https://ss64.com/bash/sort.html) arranges
    everything alphabetically, or *Sort text files. Sort, merge, or
    compare all the lines from the files given (or standard input.)*.

2.  The `uniq -c` command reduces each file to the [unique name and
    count](https://ss64.com/bash/uniq.html).

3.  The second [`sort -r`](https://ss64.com/bash/sort.html) puts the
    highest numbers to the top, or *reverse the result of comparison, so
    that lines with greater key values appear earlier in the output
    instead of later*.

<!-- end list -->

``` bash
# change dir
cd downloads/ggplot2 
# test the next
git log --format=format: --name-only | egrep -v '^$' | sort | uniq -c | head -n 10
```

    #>     2 .DS_Store
    #>    34 .Rbuildignore
    #>     1 .gitattributes
    #>     2 .github/CODE_OF_CONDUCT.md
    #>     3 .github/ISSUE_TEMPLATE.md
    #>     3 .github/lock.yml
    #>     1 .github/move.yml
    #>     9 .gitignore
    #>    49 .travis.yml
    #>     7 ANNOUNCE

Now these contents are sorted.

``` bash
# change dir
cd downloads/ggplot2 
# test the next
git log --format=format: --name-only | egrep -v '^$' | sort | uniq -c | head -n 20
```

    #>     2 .DS_Store
    #>    34 .Rbuildignore
    #>     1 .gitattributes
    #>     2 .github/CODE_OF_CONDUCT.md
    #>     3 .github/ISSUE_TEMPLATE.md
    #>     3 .github/lock.yml
    #>     1 .github/move.yml
    #>     9 .gitignore
    #>    49 .travis.yml
    #>     7 ANNOUNCE
    #>    32 CHANGELOG
    #>     1 CODE_OF_CONDUCT.md
    #>     6 CONTRIBUTING.md
    #>   301 DESCRIPTION
    #>     5 GOVERNANCE.md
    #>     2 ISSUE_TEMPLATE.md
    #>     1 LICENSE
    #>     1 LICENSE.md
    #>   267 NAMESPACE
    #>   669 NEWS

I can ignore the `sort: Broken pipe` message, because I am only viewing
the output here. So now we know to get the output from the `git log`. We
can create a new file called `file_name_counts.txt` and send the results
to this file.

``` bash
# change dir
cd downloads/ggplot2 
# create new file
touch "file_name_counts.txt"
# verify 
ls
```

    #>  CODE_OF_CONDUCT.md
    #>  CONTRIBUTING.md
    #>  DESCRIPTION
    #>  GOVERNANCE.md
    #>  ISSUE_TEMPLATE.md
    #>  LICENSE
    #>  LICENSE.md
    #>  NAMESPACE
    #>  NEWS
    #>  NEWS.md
    #>  R
    #>  README.Rmd
    #>  README.md
    #>  _pkgdown.yml
    #>  appveyor.yml
    #>  codecov.yml
    #>  cran-comments.md
    #>  data
    #>  data-raw
    #>  file_name_counts.txt
    #>  ggplot2.Rproj
    #>  icons
    #>  inst
    #>  man
    #>  pkgdown
    #>  revdep
    #>  tests
    #>  vignettes

We created the file, now we have to put the output into it with the next
chunk.

``` bash
# change dir
cd downloads/ggplot2 
# repeat commands and send to new file
git log --format=format: --name-only | egrep -v '^$' | sort | uniq -c | sort -r >> "file_name_counts.txt"
```

Now we will move this file into current directory and read them into R.

``` r
# check current location
# fs::dir_ls("../ggplot2")
fs::file_move(path = "downloads/ggplot2/file_name_counts.txt", 
              new_path = paste0("data/", 
                                base::noquote(lubridate::today()), 
                                "-file_name_counts.txt"))
# verify new location
fs::dir_ls("data")
```

    #>  data/2020-01-15-GitFileCount.csv     data/2020-01-15-author_summary.txt   
    #>  data/2020-01-15-file_name_counts.txt data/2020-02-10-file_name_counts.txt 
    #>  data/README.md

Now we can load these data into R.

``` r
GitFileCount <- readr::read_delim(file = paste0("data/", 
                                            base::noquote(lubridate::today()), 
                                            "-file_name_counts.txt"),
                                         delim = " ", 
                                         skip = 1, 
                                  # column names
                                         col_names = c("file_changes", 
                                                       "gitlog_path"))
```

    #>  Parsed with column specification:
    #>  cols(
    #>    file_changes = col_character(),
    #>    gitlog_path = col_character()
    #>  )

Now we have a data fame with the files and their total number of
changes.

``` r
GitFileCount %>% skimr::skim()
```

|                                                  |            |
| :----------------------------------------------- | :--------- |
| Name                                             | Piped data |
| Number of rows                                   | 1797       |
| Number of columns                                | 2          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |            |
| Column type frequency:                           |            |
| character                                        | 2          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |            |
| Group variables                                  | None       |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| file\_changes  |          0 |              1 |   4 |   4 |     0 |       101 |       1797 |
| gitlog\_path   |          0 |              1 |   6 |  92 |     0 |      1797 |          0 |

These data are showing the `gitlog_path`, so we will create a new
variable with only the `filename`.

``` r
GitFileCount <- GitFileCount %>% 
  dplyr::mutate(filename = base::basename(gitlog_path))
GitFileCount$filename %>% utils::head()
```

    #>  [1] "NEWS.md"     "DESCRIPTION" "NAMESPACE"   "layer.r"     "scale-.r"   
    #>  [6] "theme.r"

We’ll make some changes to the variables so they’re easier to plot.

``` r
GitFileCount <- GitFileCount %>% 
  dplyr::mutate(file_changes = as.numeric(file_changes),
                filename = as.factor(filename)) 
GitFileCount %>% dplyr::glimpse(78)
```

    #>  Observations: 1,797
    #>  Variables: 3
    #>  $ file_changes <dbl> 377, 301, 267, 228, 178, 172, 167, 156, 149, 133, 121,…
    #>  $ gitlog_path  <chr> "NEWS.md", "DESCRIPTION", "NAMESPACE", "R/layer.r", "R…
    #>  $ filename     <fct> NEWS.md, DESCRIPTION, NAMESPACE, layer.r, scale-.r, th…

# Visualize file changes

Below we set a theme for some better looking graphics.

``` r
ggplot2::theme_set(hrbrthemes::theme_ipsum_tw(
  base_size = 10,
  strip_text_size = 11,
  axis_title_size = 13,
  plot_title_size = 17,
  subtitle_size = 13,
  base_family = "EnvyCodeR",
  # "JosefinSans-LightItalic"
  strip_text_family = "TitilliumWeb-Regular",
  axis_title_family = "TitilliumWeb-Regular",
  subtitle_family = "TitilliumWeb-Regular",
  plot_title_family = "JosefinSans-Regular"
))
```

The graph below is a Cleveland dot plot of the files that had more than
75 changes.

``` r
# define labs first!
file_count_labs <- ggplot2::labs(
    y = "Number of file changes",
    x = "Name of file",
    title = "File changes from git log",
    subtitle = "ggplot2 files with > 75 changes",
    caption = "from git log --format=format: --name-only") 
# now plot these data in a scatter plot
GitFileCount %>% 
  dplyr::filter(file_changes > 75) %>%  
  ggplot2::ggplot(aes(x = fct_reorder(.f = filename,
                             .x = file_changes),
             y = file_changes)) +
  ggplot2::geom_point() + 
  ggplot2::coord_flip() +
  file_count_labs
```

![](figs/graph-file-counts-1.png)<!-- -->

This makes sense, because the `NEWS`, `DESCRIPTION`, and `NAMESPACE` are
the most commonly touched files.

## Next steps

In the next section (`02-counting-lines-of-code.Rmd`), we will be
counting the lines of code in each file.

``` r
# ls()
readr::write_csv(as.data.frame(GitFileCount), 
                 path = paste0("data/", 
                         base::noquote(lubridate::today()), 
                           "-GitFileCount.csv"))
fs::dir_tree("data")
```

    #>  data
    #>  ├── 2020-01-15-GitFileCount.csv
    #>  ├── 2020-01-15-author_summary.txt
    #>  ├── 2020-01-15-file_name_counts.txt
    #>  ├── 2020-02-10-GitFileCount.csv
    #>  ├── 2020-02-10-file_name_counts.txt
    #>  └── README.md
